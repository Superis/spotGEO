 Εφαρμογή μερικών ακόμα μεθόδων σε επίπεδο classifier. Τα αρχεία : 
 
 classifiers-Stacking.ipynb -> Εκπαιδεύουμε ένα stacking classifier θεωρώντας ως θετικά τα pixels που βρίσκονται στο annotation file και διαλέγοντας randomly αρνητικά δείγματα από τα
 υπόλοιπα μέρη της εικόνας, με εξαίρεση τα pixels που αποτελούν θετικά αλλά και αυτά που βρίσκονται πολύ κοντά τους. Ελέγχοντας τα αποτελέσματα σε ένα ξεχωριστό test-set που
 κατασκευάζεται με τον ίδιο τρόπο, αφού παρατηρήσουμε τα αποτελέσματα, τροποποιούμε το training set και προσθέτουμε όλα εκείνα τα δείγματα τα οποία ταξινομούνται λάθος, 
 false positives και false negatives. Επανεκπαιδεύουμε και τσεκάρουμε τη νέα αποτελεσματικότητα της μεθόδου σε ένα test set. Μπορούμε να χρησιμοποιήσουμε το predict_probabilities
 ώστε να διαλέξουμε ένα διαφορετικό κατώφλι θεώρησης ως θετικών δειγμάτων για να ισορροπήσουμε καλύτερα recall και precision.
 
 ΜanualStacking+ActiveLearnSeperately.ipynb -> Ουσιαστικά είναι τα ίδια βήματα αλλά αυτή τη φορά εφαρμόζουμε το stacking hardcoded για να προηγηθεί η μέθοδος Active Learning και σε
 κάθε ταξινομητή ξεχωριστά. Εκπαίδευση των τριών classifiers,active inclusion of negatives, επανεκπαίδευση. Το ίδιο ακριβώς έπειτα με βάση τις πιθανότητες τους για έναν Logistic
 Regression Classifier.
 
 Stacking-NeighborMetaClassifier.ipynb -> Αφού εκπαιδεύσουμε ένα απλό ταξινομητή όπως τους παραπάνω(SVM), φτιάχνουμε ένα νέο dataset για έναν άλλο classifier, του οποίου τα 
 δεδομένα είναι οι προβλέψεις του προηγούμενου. Δηλαδή για ένα pixel, τα δεδομένα εισόδου του θα είναι οι πιθανότητες που δίνει ο πρώτος ταξινομητής για αυτόν και τα γειτονικά του
 να είναι θετικά.
 
 SubmissionStacking95-80.ipynb -> Μια πρόβλεψη σε κομμάτι 10 εικόνων του training set για να δούμε χρόνο εκτέλεσης και απόδοση σε σχέση με την τελική εκτίμηση των αντικειμένων.
 
 
 Καλύτερα αποτελέσματα στα παραπάνω δίνει η πρώτη μέθοδος με precision στο 95% για τη θετική κλάση και recall στο 80%, ενώ το αποτέλεσμα σε ένα μικρό υποσύνολο του training set των
 εικόνων είναι στo 1-F1 = 0.88
 Παρόλο δηλαδή που η αποτελεσματικότητα του είναι πολύ μεγάλη, όπως και το recall-precision της θετικής κλάσης αρκετά αυξημένα δεν έχει εξαιρετικά αποτελέσματα.
 Κι αυτό πχ γιατί μια εικόνα που αποτελείται από 300.000 pixels τα οποία σχεδόν όλα είναι αρνητικά με ελάχιστα θετικά, ακόμα και με 99.99% recall στην αρνητική κλάση, θα δώσει 30 
 false positive pixels(τα οποία αντίστοιχα θα είναι λιγότερα αφού μεταφραστούν σε objects) αλλά που και πάλι θα επηρεάσουν αρνητικά το measure σε μεγάλο βαθμό.
 Συγκεκριμένα σε αυτό το αρκετά μικρό δείγμα έχουμε από την εκτίμηση : 
    TP 58 FP 840 FN 42
    Precision = 0.0645879732739421,  Recall = 0.58
