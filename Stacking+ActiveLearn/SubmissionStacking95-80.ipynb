{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "sclf = joblib.load('Stacking95-80.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score\n",
    "\n",
    "import itertools\n",
    "\n",
    "import random\n",
    "\n",
    "from skimage import measure\n",
    "import dill\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotation_file(path):\n",
    "    with open(path) as annotation_file:\n",
    "        annotation_list = json.load(annotation_file)\n",
    "    # Transform list of annotations into dictionary\n",
    "    annotation_dict = {}\n",
    "    for annotation in annotation_list:\n",
    "        sequence_id = annotation['sequence_id']\n",
    "        if sequence_id not in annotation_dict:\n",
    "            annotation_dict[sequence_id] = {}\n",
    "        annotation_dict[sequence_id][annotation['frame']] = annotation['object_coords']\n",
    "    return annotation_dict\n",
    "\n",
    "train_annotation=read_annotation_file('geoSatellites/train_anno.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "#function to choose a negative sample randomly from an image, with restriction of not being the positive ones or near to them\n",
    "def random_different_coordinates(coords, size_x, size_y, pad,cond):\n",
    "    \"\"\" Returns a random set of coordinates that is different from the provided coordinates, \n",
    "    within the specified bounds.\n",
    "    The pad parameter avoids coordinates near the bounds.\"\"\"\n",
    "    good = False\n",
    "    while not good:\n",
    "        good = True\n",
    "        c1 = random.randint(pad + 1, size_x - (pad + 1))\n",
    "        c2 = random.randint(pad + 1, size_y -( pad + 1))\n",
    "        \n",
    "        #We choose negative samples in a manner that neither positive pixels, nor pixels in the around area of them are chosen\n",
    "        #That's why we feed with the boolean cond=true if we don't want to choose the neighborhood pixels\n",
    "        if cond:\n",
    "            for c in coords:\n",
    "                coordset_0 = range(int(c[0])-1,int(c[0])+2)\n",
    "                coordset_1 = range(int(c[1])-1,int(c[1])+2)\n",
    "                if c1 in coordset_0 and c2 in coordset_1:\n",
    "                    good = False\n",
    "                    break\n",
    "        else:\n",
    "            for c in coords:\n",
    "                if c1==c[0] and c2==c[1]:\n",
    "                    good = False\n",
    "                    break\n",
    "    return (c1,c2)\n",
    "\n",
    "#This function returns the training features we will use (a square array of pixels in area of distance<=radius ) \n",
    "\n",
    "def extract_neighborhood(x, y, arr, radius):\n",
    "    \"\"\" Returns a 1-d array of the values within a radius of the x,y coordinates given \"\"\"\n",
    "    return arr[(x - radius) : (x + radius + 1), (y - radius) : (y + radius + 1)].ravel()\n",
    "\n",
    "#check if we can include the pixel, or it's in the edges and we can't have its neighborhood\n",
    "\n",
    "def check_coordinate_validity(x, y, size_x, size_y, pad):\n",
    "    \"\"\" Check if a coordinate is not too close to the image edge \"\"\"\n",
    "    return x >= pad and y >= pad and x + pad < size_x and y + pad < size_y\n",
    "\n",
    "#Append to training set every positive sample in the given images and a given number of negative samples\n",
    "\n",
    "def generate_labeled_data(image_path, annotation, nb_false, radius,cond):\n",
    "    \"\"\" For one frame and one annotation array, returns a list of labels \n",
    "    (1 for true object and 0 for false) and the corresponding features as an array.\n",
    "    nb_false controls the number of false samples\n",
    "    radius defines the size of the sliding window (e.g. radius of 1 gives a 3x3 window)\"\"\"\n",
    "    features,labels = [],[]\n",
    "    im_array = read_image(image_path)\n",
    "    # True samples\n",
    "    for obj in annotation:\n",
    "        obj = [int(x + .5) for x in obj] #Project the floating coordinate values onto integer pixel coordinates.\n",
    "        # For some reason the order of coordinates is inverted in the annotation files\n",
    "        if check_coordinate_validity(obj[1],obj[0],im_array.shape[0],im_array.shape[1],radius):\n",
    "            features.append(extract_neighborhood(obj[1],obj[0],im_array,radius))\n",
    "            labels.append(1)\n",
    "            #features.append(extract_neighborhood(obj[1],obj[0],im_array,radius))\n",
    "            #labels.append(1)\n",
    "    # False samples\n",
    "    for i in range(nb_false):\n",
    "        c = random_different_coordinates(annotation,im_array.shape[1],im_array.shape[0],radius,cond)\n",
    "        features.append(extract_neighborhood(c[1],c[0],im_array,radius))\n",
    "        labels.append(0)\n",
    "    return np.array(labels),np.stack(features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labeled_set(annotation_array, path, sequence_id_list, radius, nb_false,cond):\n",
    "    # Generate labeled data for a list of sequences in a given path\n",
    "    labels,features = [],[]\n",
    "    for seq_id in sequence_id_list:\n",
    "        for frame_id in range(1,6):\n",
    "            d = generate_labeled_data(f\"{path}{seq_id}/{frame_id}.png\",\n",
    "                                    annotation_array[seq_id][frame_id],\n",
    "                                    nb_false,\n",
    "                                    radius,cond)\n",
    "            labels.append(d[0])\n",
    "            features.append(d[1])\n",
    "    return np.concatenate(labels,axis=0), np.transpose(np.concatenate(features,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    return plt.imread(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(im, model, radius):\n",
    "    n_features=(2*radius+1)**2 #Total number of pixels in the neighborhood\n",
    "    feat_array=np.zeros((im.shape[0],im.shape[1],n_features))\n",
    "    for x in range(radius+1,im.shape[0]-(radius+1)):\n",
    "        for y in range(radius+1,im.shape[1]-(radius+1)):\n",
    "            feat_array[x,y,:]=extract_neighborhood(x,y,im,radius)\n",
    "    all_pixels=feat_array.reshape(im.shape[0]*im.shape[1],n_features)\n",
    "    pred_pixels=model.predict(all_pixels).astype(np.bool_)\n",
    "    pred_image=pred_pixels.reshape(im.shape[0],im.shape[1])\n",
    "    return pred_image\n",
    "def extract_centroids(pred, bg):\n",
    "    conn_comp=measure.label(pred, background=bg)\n",
    "    object_dict=defaultdict(list) #Keys are the indices of the connected components and values are arrrays of their pixel coordinates \n",
    "    for (x,y),label in np.ndenumerate(conn_comp):\n",
    "            if label != bg:\n",
    "                object_dict[label].append([x,y])\n",
    "    # Mean coordinate vector for each object, except the \"0\" label which is the background\n",
    "    centroids={label: np.mean(np.stack(coords),axis=0) for label,coords in object_dict.items()}\n",
    "    object_sizes={label: len(coords) for label,coords in object_dict.items()}\n",
    "    return centroids, object_sizes\n",
    "def filter_large_objects(centroids,object_sizes, min_size,max_size):\n",
    "    small_centroids={}\n",
    "    for label,coords in centroids.items():\n",
    "            if object_sizes[label] <= max_size and object_sizes[label]>min_size:\n",
    "                small_centroids[label]=coords\n",
    "    return small_centroids\n",
    "\n",
    "def predict_objects(sequence_id, frame_id, model, radius, min_size,max_size):\n",
    "    print(sequence_id)\n",
    "    test_image = plt.imread(f\"geoSatellites/train/{sequence_id}/{frame_id}.png\")\n",
    "    test_pred=classify_image(test_image, model, radius)\n",
    "    test_centroids, test_sizes = extract_centroids(test_pred, 0)\n",
    "    test_centroids = filter_large_objects(test_centroids, test_sizes,min_size, max_size)\n",
    "    # Switch x and y coordinates for submission\n",
    "    if len(test_centroids.values()) > 0:\n",
    "        sub=np.concatenate([c[np.array([1,0])].reshape((1,2)) for c in test_centroids.values()])\n",
    "        #np array converted to list for json seralization, truncated to the first 30 elements\n",
    "        return sub.tolist()[0:30]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202\n",
      "Frame: 198.48847436904907\n",
      "1202\n",
      "Frame: 193.1818130016327\n",
      "1202\n",
      "Frame: 193.1761350631714\n",
      "1202\n",
      "Frame: 191.89705991744995\n",
      "1202\n",
      "Frame: 194.81970715522766\n",
      "Sequence: 971.5651886463165\n",
      "1203\n",
      "Frame: 196.01037168502808\n",
      "1203\n",
      "Frame: 197.9352102279663\n",
      "1203\n",
      "Frame: 195.36734533309937\n",
      "1203\n",
      "Frame: 195.12195992469788\n",
      "1203\n",
      "Frame: 196.48712968826294\n",
      "Sequence: 980.925012588501\n",
      "1204\n",
      "Frame: 192.64844489097595\n",
      "1204\n",
      "Frame: 192.84836292266846\n",
      "1204\n",
      "Frame: 192.7104651927948\n",
      "1204\n",
      "Frame: 192.54259514808655\n",
      "1204\n",
      "Frame: 192.66643142700195\n",
      "Sequence: 963.4202969074249\n",
      "1205\n",
      "Frame: 193.00304675102234\n",
      "1205\n",
      "Frame: 193.66933917999268\n",
      "1205\n",
      "Frame: 193.48781085014343\n",
      "1205\n",
      "Frame: 194.27647376060486\n",
      "1205\n",
      "Frame: 193.2038927078247\n",
      "Sequence: 967.6445379257202\n",
      "1206\n",
      "Frame: 192.31293654441833\n",
      "1206\n",
      "Frame: 190.24693036079407\n",
      "1206\n",
      "Frame: 192.24490904808044\n",
      "1206\n",
      "Frame: 194.6582555770874\n",
      "1206\n",
      "Frame: 191.6450653076172\n",
      "Sequence: 961.1110942363739\n",
      "1207\n",
      "Frame: 195.14955234527588\n",
      "1207\n",
      "Frame: 195.33100366592407\n",
      "1207\n",
      "Frame: 194.1865336894989\n",
      "1207\n",
      "Frame: 196.22556734085083\n",
      "1207\n",
      "Frame: 194.04693150520325\n",
      "Sequence: 974.9435837268829\n",
      "1208\n",
      "Frame: 192.33356881141663\n",
      "1208\n",
      "Frame: 191.50434041023254\n",
      "1208\n",
      "Frame: 194.0192425251007\n",
      "1208\n",
      "Frame: 192.91132640838623\n",
      "1208\n",
      "Frame: 192.78040385246277\n",
      "Sequence: 963.5518798828125\n",
      "1209\n",
      "Frame: 190.82790970802307\n",
      "1209\n",
      "Frame: 192.1901388168335\n",
      "1209\n",
      "Frame: 193.10915660858154\n",
      "1209\n",
      "Frame: 190.9345576763153\n",
      "1209\n",
      "Frame: 189.9731001853943\n",
      "Sequence: 957.0388612747192\n",
      "1210\n",
      "Frame: 191.71906542778015\n",
      "1210\n",
      "Frame: 189.65560626983643\n",
      "1210\n",
      "Frame: 189.40155148506165\n",
      "1210\n",
      "Frame: 191.90000343322754\n",
      "1210\n",
      "Frame: 193.45499324798584\n",
      "Sequence: 956.1342158317566\n",
      "8696.426230192184\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "sequencerange = range(1202,1211)\n",
    "framerange = range(1,6)\n",
    "sub_list = []\n",
    "for myseq in sequencerange:\n",
    "    seq_time = time.time()\n",
    "    for myframe in framerange:\n",
    "        fr_time = time.time()\n",
    "        sub_list.append(predict_objects(myseq,myframe,sclf,3,0,5))\n",
    "        print('Frame: '+str(time.time()-fr_time))\n",
    "        #print(len(sub_list))\n",
    "        #print(sub_list[0:5])\n",
    "    print('Sequence: '+str(time.time()-seq_time))\n",
    "submission=[]\n",
    "for s in range(1202,1211):\n",
    "    #print(s)\n",
    "    for fr in range(1,6):\n",
    "        if s in sequencerange:\n",
    "            submission.append({\"sequence_id\" : s, \n",
    "                                    \"frame\" : fr, \n",
    "                                    \"num_objects\" : len(sub_list[(s-1202)*5 + fr-1]), \n",
    "                                    \"object_coords\" : sub_list[(s-1202)*5 + fr-1]})\n",
    "        else:\n",
    "            submission.append({\"sequence_id\" : s,\n",
    "                                    \"frame\" : fr,\n",
    "                                    \"num_objects\" : 0,\n",
    "                                    \"object_coords\" : []})\n",
    "with open('my_submissionSmall_Stack95-80_train1202-1210flt1-5.json', 'w') as outfile:\n",
    "    json.dump(submission, outfile)\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
